{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X86FZ0wJIvPa",
    "outputId": "e5b569d2-4a7e-45dc-98b6-57d0f3167f20"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XhOpHkIrIvPb"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Coronavirus Tweets.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "9RD7f0fPIvPc",
    "outputId": "d2f95372-28e9-4006-84fe-8d7446f12c1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>country_code</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>1.331840e+08</td>\n",
       "      <td>2020-03-09T00:00:00Z</td>\n",
       "      <td>EcuadorTV</td>\n",
       "      <td>HOY | 20H00\\n@CataAndramuno, ministra de @Salu...</td>\n",
       "      <td>Twitter Media Studio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527405</td>\n",
       "      <td>1166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-04-15T06:31:39Z</td>\n",
       "      <td>True</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>1.186300e+18</td>\n",
       "      <td>2020-03-09T00:00:00Z</td>\n",
       "      <td>DanielAnthonyL2</td>\n",
       "      <td>ç³å®¶åºçä¸ä¸ªå°å­©ãå¯æåï¼\\n\\n#å...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-21T14:56:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>zh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>9.779450e+17</td>\n",
       "      <td>2020-03-09T00:00:00Z</td>\n",
       "      <td>deepnews_ai</td>\n",
       "      <td>During a health scare like the #CoronavirusOut...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1096</td>\n",
       "      <td>835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-25T16:28:09Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>2.700096e+08</td>\n",
       "      <td>2020-03-09T00:00:14Z</td>\n",
       "      <td>kwekwayel</td>\n",
       "      <td>@Twitter please update reporting to include fa...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>783214.0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202</td>\n",
       "      <td>624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-21T21:03:44Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>8.462100e+17</td>\n",
       "      <td>2020-03-09T00:00:28Z</td>\n",
       "      <td>mystylehfb</td>\n",
       "      <td>Germ Guardian Pluggable Air Purifier &amp;amp; San...</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5777</td>\n",
       "      <td>6332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-27T04:00:34Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>1.111290e+18</td>\n",
       "      <td>2020-03-09T00:00:36Z</td>\n",
       "      <td>SaintBrothel</td>\n",
       "      <td>Simple math proves the Chinese government is l...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3725</td>\n",
       "      <td>3812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-28T15:34:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>9.031460e+17</td>\n",
       "      <td>2020-03-09T00:00:38Z</td>\n",
       "      <td>PatriciaSbd</td>\n",
       "      <td>Es increÃ­ble la incompetencia e irresponsabil...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>ES</td>\n",
       "      <td>Sabadell, Spain</td>\n",
       "      <td>city</td>\n",
       "      <td>6341</td>\n",
       "      <td>3576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-31T06:44:38Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>1.222270e+18</td>\n",
       "      <td>2020-03-09T00:00:42Z</td>\n",
       "      <td>BytesCrypto</td>\n",
       "      <td>#CoronavirusOutbreak\\nð®ð¹ 7 381\\nð«ð·...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-28T21:40:48Z</td>\n",
       "      <td>False</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>2.706523e+08</td>\n",
       "      <td>2020-03-09T00:00:42Z</td>\n",
       "      <td>BlackPearl_Inc</td>\n",
       "      <td>Classes were suspended in the following cities...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399</td>\n",
       "      <td>2832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-23T00:50:38Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>2.706523e+08</td>\n",
       "      <td>2020-03-09T00:00:43Z</td>\n",
       "      <td>BlackPearl_Inc</td>\n",
       "      <td>Manila Tytana Colleges\\n\\nTrinity University o...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>270652316.0</td>\n",
       "      <td>BlackPearl_Inc</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399</td>\n",
       "      <td>2832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-23T00:50:38Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      status_id       user_id            created_at      screen_name  \\\n",
       "0  1.236800e+18  1.331840e+08  2020-03-09T00:00:00Z        EcuadorTV   \n",
       "1  1.236800e+18  1.186300e+18  2020-03-09T00:00:00Z  DanielAnthonyL2   \n",
       "2  1.236800e+18  9.779450e+17  2020-03-09T00:00:00Z      deepnews_ai   \n",
       "3  1.236800e+18  2.700096e+08  2020-03-09T00:00:14Z        kwekwayel   \n",
       "4  1.236800e+18  8.462100e+17  2020-03-09T00:00:28Z       mystylehfb   \n",
       "5  1.236800e+18  1.111290e+18  2020-03-09T00:00:36Z     SaintBrothel   \n",
       "6  1.236800e+18  9.031460e+17  2020-03-09T00:00:38Z      PatriciaSbd   \n",
       "7  1.236800e+18  1.222270e+18  2020-03-09T00:00:42Z      BytesCrypto   \n",
       "8  1.236800e+18  2.706523e+08  2020-03-09T00:00:42Z   BlackPearl_Inc   \n",
       "9  1.236800e+18  2.706523e+08  2020-03-09T00:00:43Z   BlackPearl_Inc   \n",
       "\n",
       "                                                text                source  \\\n",
       "0  HOY | 20H00\\n@CataAndramuno, ministra de @Salu...  Twitter Media Studio   \n",
       "1  ç³å®¶åºçä¸ä¸ªå°å­©ãå¯æåï¼\\n\\n#å...             TweetDeck   \n",
       "2  During a health scare like the #CoronavirusOut...             TweetDeck   \n",
       "3  @Twitter please update reporting to include fa...    Twitter for iPhone   \n",
       "4  Germ Guardian Pluggable Air Purifier &amp; San...                Buffer   \n",
       "5  Simple math proves the Chinese government is l...    Twitter for iPhone   \n",
       "6  Es increÃ­ble la incompetencia e irresponsabil...   Twitter for Android   \n",
       "7  #CoronavirusOutbreak\\nð®ð¹ 7 381\\nð«ð·...   Twitter for Android   \n",
       "8  Classes were suspended in the following cities...       Twitter Web App   \n",
       "9  Manila Tytana Colleges\\n\\nTrinity University o...       Twitter Web App   \n",
       "\n",
       "   reply_to_status_id  reply_to_user_id reply_to_screen_name  is_quote  ...  \\\n",
       "0                 NaN               NaN                  NaN     False  ...   \n",
       "1                 NaN               NaN                  NaN     False  ...   \n",
       "2                 NaN               NaN                  NaN      True  ...   \n",
       "3                 NaN          783214.0              Twitter     False  ...   \n",
       "4                 NaN               NaN                  NaN     False  ...   \n",
       "5                 NaN               NaN                  NaN      True  ...   \n",
       "6                 NaN               NaN                  NaN      True  ...   \n",
       "7                 NaN               NaN                  NaN     False  ...   \n",
       "8                 NaN               NaN                  NaN     False  ...   \n",
       "9        1.236800e+18       270652316.0       BlackPearl_Inc     False  ...   \n",
       "\n",
       "   retweet_count  country_code  place_full_name place_type followers_count  \\\n",
       "0              5           NaN              NaN        NaN          527405   \n",
       "1              2           NaN              NaN        NaN              85   \n",
       "2              0           NaN              NaN        NaN            1096   \n",
       "3              0           NaN              NaN        NaN             202   \n",
       "4              0           NaN              NaN        NaN            5777   \n",
       "5              0           NaN              NaN        NaN            3725   \n",
       "6              8            ES  Sabadell, Spain       city            6341   \n",
       "7              0           NaN              NaN        NaN              41   \n",
       "8              0           NaN              NaN        NaN             399   \n",
       "9              0           NaN              NaN        NaN             399   \n",
       "\n",
       "  friends_count  account_lang    account_created_at  verified lang  \n",
       "0          1166           NaN  2010-04-15T06:31:39Z      True   es  \n",
       "1           508           NaN  2019-10-21T14:56:27Z     False   zh  \n",
       "2           835           NaN  2018-03-25T16:28:09Z     False   en  \n",
       "3           624           NaN  2011-03-21T21:03:44Z     False   en  \n",
       "4          6332           NaN  2017-03-27T04:00:34Z     False   en  \n",
       "5          3812           NaN  2019-03-28T15:34:27Z     False   en  \n",
       "6          3576           NaN  2017-08-31T06:44:38Z     False   es  \n",
       "7           157           NaN  2020-01-28T21:40:48Z     False  und  \n",
       "8          2832           NaN  2011-03-23T00:50:38Z     False   en  \n",
       "9          2832           NaN  2011-03-23T00:50:38Z     False   en  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxaR3PTsIvPc",
    "outputId": "379623ff-c062-439c-cb16-ec613ac7e33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 463418 entries, 0 to 463417\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   status_id             463418 non-null  float64\n",
      " 1   user_id               463418 non-null  float64\n",
      " 2   created_at            463418 non-null  object \n",
      " 3   screen_name           463418 non-null  object \n",
      " 4   text                  463418 non-null  object \n",
      " 5   source                463418 non-null  object \n",
      " 6   reply_to_status_id    69127 non-null   float64\n",
      " 7   reply_to_user_id      81053 non-null   float64\n",
      " 8   reply_to_screen_name  81053 non-null   object \n",
      " 9   is_quote              463418 non-null  bool   \n",
      " 10  is_retweet            463418 non-null  bool   \n",
      " 11  favourites_count      463418 non-null  int64  \n",
      " 12  retweet_count         463418 non-null  int64  \n",
      " 13  country_code          21973 non-null   object \n",
      " 14  place_full_name       22009 non-null   object \n",
      " 15  place_type            22009 non-null   object \n",
      " 16  followers_count       463418 non-null  int64  \n",
      " 17  friends_count         463418 non-null  int64  \n",
      " 18  account_lang          0 non-null       float64\n",
      " 19  account_created_at    463418 non-null  object \n",
      " 20  verified              463418 non-null  bool   \n",
      " 21  lang                  463418 non-null  object \n",
      "dtypes: bool(3), float64(5), int64(4), object(10)\n",
      "memory usage: 68.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EBxcfZL2IvPc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#To display plots inline; within the notebook window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-RRKrCtIvPc",
    "outputId": "0492bc28-88d0-4211-b7fd-1b1daae1f324"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading vader_lexicon: <urlopen error [WinError\n",
      "[nltk_data]     10060] A connection attempt failed because the\n",
      "[nltk_data]     connected party did not properly respond after a\n",
      "[nltk_data]     period of time, or established connection failed\n",
      "[nltk_data]     because connected host has failed to respond>\n",
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "EMOt_DH2IvPd",
    "outputId": "32143c31-d6c9-45a7-fe35-d7f504123804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>country_code</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>1.331840e+08</td>\n",
       "      <td>2020-03-09T00:00:00Z</td>\n",
       "      <td>EcuadorTV</td>\n",
       "      <td>HOY | 20H00\\n@CataAndramuno, ministra de @Salu...</td>\n",
       "      <td>Twitter Media Studio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527405</td>\n",
       "      <td>1166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-04-15T06:31:39Z</td>\n",
       "      <td>True</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>1.186300e+18</td>\n",
       "      <td>2020-03-09T00:00:00Z</td>\n",
       "      <td>DanielAnthonyL2</td>\n",
       "      <td>ç³å®¶åºçä¸ä¸ªå°å­©ãå¯æåï¼\\n\\n#å...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-21T14:56:27Z</td>\n",
       "      <td>False</td>\n",
       "      <td>zh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>9.779450e+17</td>\n",
       "      <td>2020-03-09T00:00:00Z</td>\n",
       "      <td>deepnews_ai</td>\n",
       "      <td>During a health scare like the #CoronavirusOut...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1096</td>\n",
       "      <td>835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-25T16:28:09Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>2.700096e+08</td>\n",
       "      <td>2020-03-09T00:00:14Z</td>\n",
       "      <td>kwekwayel</td>\n",
       "      <td>@Twitter please update reporting to include fa...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>783214.0</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202</td>\n",
       "      <td>624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-21T21:03:44Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.236800e+18</td>\n",
       "      <td>8.462100e+17</td>\n",
       "      <td>2020-03-09T00:00:28Z</td>\n",
       "      <td>mystylehfb</td>\n",
       "      <td>Germ Guardian Pluggable Air Purifier &amp;amp; San...</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5777</td>\n",
       "      <td>6332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-03-27T04:00:34Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      status_id       user_id            created_at      screen_name  \\\n",
       "0  1.236800e+18  1.331840e+08  2020-03-09T00:00:00Z        EcuadorTV   \n",
       "1  1.236800e+18  1.186300e+18  2020-03-09T00:00:00Z  DanielAnthonyL2   \n",
       "2  1.236800e+18  9.779450e+17  2020-03-09T00:00:00Z      deepnews_ai   \n",
       "3  1.236800e+18  2.700096e+08  2020-03-09T00:00:14Z        kwekwayel   \n",
       "4  1.236800e+18  8.462100e+17  2020-03-09T00:00:28Z       mystylehfb   \n",
       "\n",
       "                                                text                source  \\\n",
       "0  HOY | 20H00\\n@CataAndramuno, ministra de @Salu...  Twitter Media Studio   \n",
       "1  ç³å®¶åºçä¸ä¸ªå°å­©ãå¯æåï¼\\n\\n#å...             TweetDeck   \n",
       "2  During a health scare like the #CoronavirusOut...             TweetDeck   \n",
       "3  @Twitter please update reporting to include fa...    Twitter for iPhone   \n",
       "4  Germ Guardian Pluggable Air Purifier &amp; San...                Buffer   \n",
       "\n",
       "   reply_to_status_id  reply_to_user_id reply_to_screen_name  is_quote  ...  \\\n",
       "0                 NaN               NaN                  NaN     False  ...   \n",
       "1                 NaN               NaN                  NaN     False  ...   \n",
       "2                 NaN               NaN                  NaN      True  ...   \n",
       "3                 NaN          783214.0              Twitter     False  ...   \n",
       "4                 NaN               NaN                  NaN     False  ...   \n",
       "\n",
       "   retweet_count  country_code  place_full_name place_type followers_count  \\\n",
       "0              5           NaN              NaN        NaN          527405   \n",
       "1              2           NaN              NaN        NaN              85   \n",
       "2              0           NaN              NaN        NaN            1096   \n",
       "3              0           NaN              NaN        NaN             202   \n",
       "4              0           NaN              NaN        NaN            5777   \n",
       "\n",
       "  friends_count  account_lang    account_created_at  verified lang  \n",
       "0          1166           NaN  2010-04-15T06:31:39Z      True   es  \n",
       "1           508           NaN  2019-10-21T14:56:27Z     False   zh  \n",
       "2           835           NaN  2018-03-25T16:28:09Z     False   en  \n",
       "3           624           NaN  2011-03-21T21:03:44Z     False   en  \n",
       "4          6332           NaN  2017-03-27T04:00:34Z     False   en  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zLNylSDhIvPd"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stop_words = set(stopwords.words('english'))     # make a set of stopwords\n",
    "vectoriser = TfidfVectorizer(stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "X0nTIIuRIvPd"
   },
   "outputs": [],
   "source": [
    "#Extracting English Tweets of all countries\n",
    "tweets= df[[\"text\",\"country_code\"]][df['lang'] == 'en'].reset_index()\n",
    "tweets.drop([\"index\"],axis=1)\n",
    "\n",
    "\n",
    "#maintain a copy of original tweets before processing it\n",
    "tweets_original = tweets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "3oadNZqNIvPd",
    "outputId": "fd4fc222-b4ef-4959-b324-1418dbbdbc2e"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollocations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize_plurals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# plot the WordCloud image                        \u001b[39;00m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m), facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\yatharth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\wordcloud\\wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\yatharth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\wordcloud\\wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    620\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\yatharth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\wordcloud\\wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    505\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[0;32m    506\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[0;32m    510\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    511\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[1;32mc:\\users\\yatharth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    669\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(font, ImageFont\u001b[38;5;241m.\u001b[39mFreeTypeFont):\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supported for TrueType fonts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    672\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[0;32m    673\u001b[0m bbox \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mgetbbox(\n\u001b[0;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[0;32m    675\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color='black',\n",
    "    max_words=100,\n",
    "    max_font_size=40,\n",
    "    scale=5,\n",
    "    random_state=1,\n",
    "    collocations=False,\n",
    "    normalize_plurals=False\n",
    ").generate(' '.join(df))\n",
    " \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor=\"None\")\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud of Corona-Tweets\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Z9DekKkzIvPe"
   },
   "outputs": [],
   "source": [
    "#Retaining only alphabets (removing all punctuations and numbers)\n",
    "tweets[\"text\"] = [re.sub('[^a-zA-Z]', ' ',i) for i in tweets[\"text\"]]\n",
    "\n",
    "\n",
    "#Converting into lower case\n",
    "tweets[\"text\"] = [i.lower() for i in tweets[\"text\"]]\n",
    "\n",
    "\n",
    "#Removing Emoticons\n",
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "tweets[\"text\"]  = [deEmojify(i) for i in tweets[\"text\"] ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Removing URLs\n",
    "def removeURLs(str):\n",
    "    ans = \"\"\n",
    "    clean_tweet1 = re.match('(.*?)http.*?\\s?(.*?)', str)\n",
    "    clean_tweet2 = re.match('(.*?)https.*?\\s?(.*?)', str)\n",
    "    if clean_tweet1:\n",
    "        ans=ans+clean_tweet1.group(1)\n",
    "        ans=ans+clean_tweet1.group(2)\n",
    "    elif clean_tweet2:\n",
    "        ans=ans+clean_tweet2.group(1)\n",
    "        ans=ans+clean_tweet2.group(2)\n",
    "    else:\n",
    "        ans = str\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda tweet: removeURLs(tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9mOKAfhzIvPe"
   },
   "outputs": [],
   "source": [
    "#Removing Stop Words\n",
    "cachedStopWords = set(stopwords.words(\"english\"))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda tweet: ' '.join([word for word in tweet.split() if word not in cachedStopWords]))\n",
    "\n",
    "\n",
    "#Define words that we do not want to Stem or Lemmatize\n",
    "specialWords = [\"coronavirus\", \"covid\",\"quarantine\",\"coronavirusoutbreak\",\"virus\",\"corona\",\"lockdown\"]\n",
    "\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "def stemWords(word):\n",
    "    if word in specialWords:\n",
    "            return word\n",
    "    else:\n",
    "        return ps.stem(word)\n",
    "       \n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda tweet: ' '.join([stemWords(word) for word in tweet.split()]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Lemmatization:\n",
    "wnl = WordNetLemmatizer()\n",
    "def lemmatizeWords(word):\n",
    "    if word in specialWords:\n",
    "            return word\n",
    "    else:\n",
    "        return wnl.lemmatize(word)\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda tweet: ' '.join([lemmatizeWords(word) for word in tweet.split()]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Preparing corpus\n",
    "corpus=[]\n",
    "corpus = [word for tweet in tweets[\"text\"] for word in tweet.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "uTTgUXVgIvPe",
    "outputId": "e67a3b17-22cd-4350-ecb4-15391a24ba8d"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# plot the WordCloud image                        \u001b[39;00m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m), facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\yatharth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\wordcloud\\wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\yatharth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\wordcloud\\wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    620\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\yatharth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\wordcloud\\wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    505\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[0;32m    506\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[0;32m    510\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    511\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[1;32mc:\\users\\yatharth\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    669\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(font, ImageFont\u001b[38;5;241m.\u001b[39mFreeTypeFont):\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supported for TrueType fonts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    672\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[0;32m    673\u001b[0m bbox \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mgetbbox(\n\u001b[0;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[0;32m    675\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color='black',\n",
    "    max_words=100,\n",
    "    max_font_size=40,\n",
    "    scale=5\n",
    ").generate(' '.join(corpus))\n",
    " \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor=\"None\")\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud of Corona-Tweets\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nsrguU3GIvPe",
    "outputId": "edca4f79-866d-4f7f-a880-3ac97696faa4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound\n",
       "0  0.125  0.549  0.325    0.6249\n",
       "1  0.000  1.000  0.000    0.0000\n",
       "2  0.000  1.000  0.000    0.0000\n",
       "3  0.000  1.000  0.000    0.0000\n",
       "4  0.175  0.825  0.000   -0.6705"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SentimentIntensityAnalyzer()\n",
    "scores = tweets[\"text\"].apply(lambda tweet: s.polarity_scores(tweet))\n",
    "scores_df = pd.DataFrame(list(scores))\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtAVts3USm8h",
    "outputId": "dfaeb248-f61c-4aef-e06d-029592a0a495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Positive Words in Tweets: 12590\n",
      "Total Negative Words in Tweets: 10244\n",
      "Total Neutral Words in Tweets: 4260338\n"
     ]
    }
   ],
   "source": [
    "pos_word_list=[]\n",
    "neu_word_list=[]\n",
    "neg_word_list=[]\n",
    "pos_word_weight=[]\n",
    "neu_word_weight=[]\n",
    "neg_word_weight=[]\n",
    "\n",
    "\n",
    "def get_word_sentiment(text):\n",
    "   \n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    #print(tokenized_text)    \n",
    "\n",
    "\n",
    "    for word in tokenized_text:\n",
    "            if (s.polarity_scores(word)['compound']) >= 0.6:\n",
    "                pos_word_list.append(word)\n",
    "                pos_word_weight.append(s.polarity_scores(word)['compound'])\n",
    "            elif (s.polarity_scores(word)['compound']) <= -0.6:\n",
    "                neg_word_list.append(word)\n",
    "                neg_word_weight.append(s.polarity_scores(word)['compound'])\n",
    "            else:\n",
    "                neu_word_list.append(word)\n",
    "                neu_word_weight.append(s.polarity_scores(word)['compound'])\n",
    "\n",
    "\n",
    "for tweet in tweets[\"text\"]:\n",
    "    get_word_sentiment(tweet)\n",
    "\n",
    "\n",
    "print('Total Positive Words in Tweets:',len(pos_word_list))\n",
    "print('Total Negative Words in Tweets:',len(neg_word_list))\n",
    "print('Total Neutral Words in Tweets:',len(neu_word_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
